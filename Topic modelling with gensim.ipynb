{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Apps\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# https://www.analyticsvidhya.com/blog/2016/08/beginners-guide-to-topic-modeling-in-python/\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "twitterDf = pd.read_csv('C:/Apps/Anaconda3/Python_workGH/Twitter Archive/tweets.csv') # my twitter archive downloaded\n",
    "documents = list(twitterDf['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\gh3n13\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\wordnet.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import nltk\n",
    "#nltk.download(\"stopwords\")\n",
    "#nltk.download(\"wordnet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = set(stopwords.words('english'))\n",
    "excl_words = set(['amp','https','rt','fom'])\n",
    "excludeWords =stop.union(excl_words)\n",
    "excludeChars = set(string.punctuation).union(set(['‘','’'])).difference(set(['@'])) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    #stop_free = \" \".join(word for word in doc.lower().split() if ((word not in excludeWords)&(word[0]!='@')) )\n",
    "    #punc_free = ''.join(ch for ch in stop_free if ch not in excludeChars)\n",
    "    #normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    \n",
    "    punc_free = ''.join(ch for ch in doc.lower() if ch not in excludeChars)\n",
    "    stop_free = \" \".join(word for word in punc_free.split() if (word not in excludeWords)&(word[0]!='@')&('htt' not in word))\n",
    "    #normalized = \" \".join(lemma.lemmatize(word) for word in stop_free.split())\n",
    "    \n",
    "    return stop_free # normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horrifying isnt seems unjust hard believe nations seem carry without second thought\n",
      "survation accurate pollster election – get right via\n",
      "greek debt crisis people cant see light end tunnel\n",
      "fear new car petroldiesel ban 23 years time smokescreen weak measures tackle 40000 deaths year from…\n",
      "reupload last nights fixlive corbyn w\n",
      "really enjoyed people different views talking crucial fleshing strengthsweaknesses arguments\n",
      "article carries nme quotes full explicitly says doesnt answer yet\n",
      "drop wind energy costs adds pressure government rethink\n",
      "marr explained labour standing forthemany challenging government forcing uturns every op…\n",
      "cant wait next time bbc rightwhinger £600000£649999 john humphrys harrumphs leader union striking t…\n"
     ]
    }
   ],
   "source": [
    "# Clean the documents\n",
    "doc_clean = [clean(doc).split() for doc in documents]  \n",
    "for i in range(10):\n",
    "    print(\" \".join(word for word in doc_clean[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our corpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(doc_clean) #.compactify()\n",
    "#dictionary.filter_extremes(keep_n=500)\n",
    "#dictionary.compactify()\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nTopics = 8\n",
    "# Creating the object for LDA model using gensim library\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "# Running and Trainign LDA model on the document term matrix.\n",
    "ldamodel = Lda(doc_term_matrix, num_topics=nTopics, id2word = dictionary, passes=20)\n",
    "Topics = ldamodel.print_topics(num_topics=nTopics, num_words=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.010*\"nhs\" + 0.009*\"us\" + 0.007*\"share\" + 0.007*\"point\" + 0.007*\"get\"')\n",
      "(1, '0.010*\"uk\" + 0.008*\"dont\" + 0.007*\"hunt\" + 0.007*\"cameron\" + 0.006*\"health\"')\n",
      "(2, '0.009*\"one\" + 0.009*\"us\" + 0.008*\"budget\" + 0.007*\"day\" + 0.006*\"nhs\"')\n",
      "(3, '0.012*\"tax\" + 0.007*\"us\" + 0.006*\"debt\" + 0.006*\"may\" + 0.006*\"people\"')\n",
      "(4, '0.015*\"labour\" + 0.011*\"corbyn\" + 0.008*\"tory\" + 0.008*\"support\" + 0.008*\"right\"')\n",
      "(5, '0.012*\"well\" + 0.007*\"labour\" + 0.006*\"news\" + 0.006*\"southampton\" + 0.006*\"tax\"')\n",
      "(6, '0.007*\"corbyn\" + 0.006*\"greece\" + 0.006*\"tory\" + 0.005*\"nhs\" + 0.005*\"public\"')\n",
      "(7, '0.009*\"labour\" + 0.007*\"sanders\" + 0.006*\"tory\" + 0.006*\"brexit\" + 0.006*\"oh\"')\n"
     ]
    }
   ],
   "source": [
    "for i in range(nTopics):\n",
    "    print(Topics[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_docs(key_word, docs):\n",
    "    results = [doc for doc in docs if key_word in doc]\n",
    "    for i in range(len(results)):\n",
    "        print(\" \".join(word for word in results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "varoufakis launches petition urging ecb draghi publish legal opinion capital controls greece\n",
      "nothing pushes closer embracing brexit ezs refusal offer meaningful debt relief greece\n",
      "mediterranean eu countries advocating taking steps toward sounds like eu army greece eumedsummit brexit\n",
      "everyone gone greece holidays\n",
      "interested everyone brexit side greece spending five years demonising us lazy feckless shyster…\n",
      "stop destroying greece debt austerity working cancelgreekdebt\n",
      "stop looting greece cancelgreekdebt\n",
      "tv guest falls asleep live debate austerity measures greece zzzzzz gr trending eurovision\n",
      "marina prentoulis member 2countries britain greece 2parties syriza labour fight europe ht…\n",
      "german vice chancellor urges debt relief greece\n",
      "labour pressure cameron help break deadlock greece creditors labourtowin eu\n",
      "greece another compelling reason british vote brexit 23rd june answer\n",
      "greece needs support helping refugees sharing responsibility closing borders answer w\n",
      "varoufakis calls recovering former finance minister greece peoplesppe\n",
      "eu undemocratic yes brexit wont stop ttip wont help greece wont help refugees\n"
     ]
    }
   ],
   "source": [
    "search_docs('greece', doc_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#nltk.download(\"words\")\n",
    "#sentence = ' '.join(doc_clean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In this interview Jon Betts tells us about his policing background\n",
      "(S\n",
      "  In/IN\n",
      "  this/DT\n",
      "  interview/NN\n",
      "  (PERSON Jon/NNP Betts/NNP)\n",
      "  tells/VBZ\n",
      "  us/PRP\n",
      "  about/IN\n",
      "  his/PRP$\n",
      "  policing/NN\n",
      "  background/NN)\n"
     ]
    }
   ],
   "source": [
    "from nltk import word_tokenize, pos_tag, ne_chunk\n",
    "sentence='In this interview Jon Betts tells us about his policing background'\n",
    "print(sentence)\n",
    "print(ne_chunk(pos_tag(word_tokenize(sentence))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IN preposition/subordinating conjunction\n",
    "DT determiner\n",
    "NN noun, singular\n",
    "NNP proper noun, singular\n",
    "VBZ verb, 3rd person sing. present\n",
    "PRP personal pronoun\n",
    "PRP$ possessive pronoun\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
